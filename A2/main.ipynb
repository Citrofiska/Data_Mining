{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Discovery of frequent itemsets and association rules\n",
    "Homework Group 54: Xu Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of discovering association rules between itemsets in a sales transaction database (a set of baskets) includes the following two sub-problems：\n",
    "\n",
    "1.Finding frequent itemsets with support at least s; \n",
    "\n",
    "2.Generating association rules with confidence at least c from the itemsets found in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataset\n",
    "The dataset is given by the assignment.\n",
    "Preprocess and save each transaction in a basket, compute the 1% of basket_num as the support threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(name):  # read in the dataset as a list of sets of transactions\n",
    "    baskets = []\n",
    "    with open(name, 'r') as f:\n",
    "        for line in f:\n",
    "            items = line.split(' ')\n",
    "            items.remove('\\n')\n",
    "            items.sort()\n",
    "            baskets.append(list(map(int, items)))\n",
    "    s = len(baskets) * 0.01\n",
    "    return baskets, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions 100000\n",
      "Support threshold 1000.0\n"
     ]
    }
   ],
   "source": [
    "baskets, s = read_data(\"T10I4D100K.dat\")\n",
    "frequent_itemsets = [] # A list of dictionaries\n",
    "print('Number of transactions', len(baskets))\n",
    "print('Support threshold', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Implement the A-priori algorithm\n",
    "The implementations below follow the general structure:\n",
    "a. pick out each item in the dataset and compute the frequent singletons\n",
    "b. generate candidate k-itemsets\n",
    "c. filter over the candidates by the support_threshold and select the frequent k-itemsets\n",
    "d. repeat step b and c until no more k-itemsets can be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step a: find frequent singletons\n",
    "def get_freq_singletons(baskets, support_threshold):\n",
    "    freq_dict = {}\n",
    "    for basket in baskets:\n",
    "        for item in basket: # pick out single item from basket\n",
    "            if item in freq_dict:\n",
    "                freq_dict[item] += 1\n",
    "            else:\n",
    "                freq_dict[item] = 1\n",
    "    singletons = [(item,) for item, count in freq_dict.items() if count >= support_threshold] \n",
    "    singletons_dict = {(item,):count for item, count in freq_dict.items() if count >= support_threshold} # (item,) is to save the key as the same type as the doubletons, tripletons, etc.\n",
    "    return singletons, singletons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent singletons:  375\n",
      "[(240,), (25,), (274,), (368,), (448,), (52,), (538,), (561,), (630,), (687,), (775,), (825,), (834,), (120,), (205,), (39,), (401,), (581,), (704,), (814,), (35,), (674,), (733,), (854,), (950,), (422,), (449,), (857,), (895,), (937,), (964,), (229,), (283,), (294,), (381,), (708,), (738,), (766,), (853,), (883,), (966,), (978,), (104,), (143,), (569,), (620,), (798,), (185,), (214,), (350,), (529,), (658,), (682,), (782,), (809,), (947,), (970,), (227,), (390,), (192,), (208,), (279,), (280,), (496,), (530,), (597,), (618,), (675,), (71,), (720,), (914,), (932,), (183,), (217,), (276,), (653,), (706,), (878,), (161,), (175,), (177,), (424,), (490,), (571,), (623,), (795,), (910,), (960,), (125,), (130,), (392,), (461,), (862,), (27,), (78,), (900,), (921,), (147,), (411,), (572,), (579,), (778,), (803,), (266,), (290,), (458,), (523,), (614,), (888,), (944,), (204,), (334,), (43,), (480,), (513,), (70,), (874,), (151,), (504,), (890,), (310,), (419,), (469,), (722,), (73,), (810,), (844,), (846,), (918,), (967,), (326,), (403,), (526,), (774,), (788,), (789,), (975,), (116,), (198,), (201,), (171,), (541,), (701,), (805,), (946,), (471,), (487,), (631,), (638,), (678,), (735,), (780,), (935,), (17,), (242,), (758,), (763,), (956,), (145,), (385,), (676,), (790,), (792,), (885,), (522,), (617,), (859,), (12,), (296,), (354,), (548,), (684,), (740,), (841,), (210,), (346,), (477,), (605,), (829,), (884,), (234,), (460,), (649,), (746,), (600,), (157,), (28,), (115,), (5,), (517,), (736,), (744,), (919,), (196,), (489,), (494,), (641,), (673,), (362,), (591,), (181,), (31,), (472,), (573,), (58,), (628,), (651,), (111,), (154,), (168,), (580,), (632,), (832,), (871,), (988,), (72,), (981,), (10,), (132,), (21,), (239,), (32,), (348,), (54,), (100,), (500,), (126,), (319,), (48,), (639,), (765,), (521,), (112,), (140,), (285,), (387,), (511,), (594,), (583,), (606,), (93,), (236,), (952,), (593,), (90,), (941,), (122,), (718,), (1,), (423,), (516,), (6,), (69,), (797,), (913,), (577,), (110,), (509,), (611,), (995,), (343,), (527,), (33,), (336,), (989,), (574,), (793,), (97,), (598,), (427,), (470,), (37,), (992,), (55,), (897,), (275,), (259,), (51,), (162,), (378,), (45,), (534,), (906,), (912,), (576,), (373,), (716,), (546,), (665,), (963,), (349,), (197,), (413,), (749,), (8,), (823,), (94,), (982,), (984,), (515,), (692,), (694,), (567,), (57,), (800,), (812,), (41,), (414,), (923,), (377,), (752,), (991,), (998,), (899,), (710,), (867,), (170,), (438,), (563,), (357,), (332,), (361,), (322,), (928,), (486,), (75,), (440,), (38,), (784,), (265,), (686,), (540,), (468,), (663,), (819,), (886,), (429,), (843,), (129,), (578,), (510,), (68,), (860,), (4,), (887,), (309,), (804,), (325,), (826,), (394,), (707,), (105,), (815,), (948,), (308,), (661,), (634,), (351,), (405,), (688,), (949,), (163,), (893,), (335,), (173,), (258,), (85,), (450,), (428,), (550,), (769,), (554,), (366,), (820,), (207,)]\n"
     ]
    }
   ],
   "source": [
    "L1, dict = get_freq_singletons(baskets, s)\n",
    "print('Number of frequent singletons: ', len(L1))\n",
    "print(L1)\n",
    "frequent_itemsets.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step b: generate all combinations of elelments in itemsets and freq_singletons\n",
    "def generate_candidates(itemsets, freq_singletons):\n",
    "    candidates = {}\n",
    "    for itemset in itemsets:\n",
    "        for singleton in freq_singletons:\n",
    "            if singleton[0] not in itemset:\n",
    "                candidate = tuple(sorted(itemset + singleton))\n",
    "                if candidate not in candidates:\n",
    "                    candidates[candidate] = 0\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step c: compute the occurence of a candidate in all baskets and filter up those with occurence >= support_threshold\n",
    "# find out checking whether a candidate is the subset of a basket is too slow. Too many candidates, especially for doubletons.\n",
    "# Implemented the other way around: generate subset of a basket with length k and check if it is a candidate\n",
    "def filter_candidates(baskets, candidates, candidate_length, support_threshold):\n",
    "    for basket in baskets:\n",
    "        sub_ks = itertools.combinations(basket, candidate_length)\n",
    "        for subk in sub_ks:\n",
    "            if subk in candidates:\n",
    "                candidates[subk] += 1\n",
    "    freq_candidates = [candidate for candidate, count in candidates.items() if count >= support_threshold]\n",
    "    dict = {candidate:count for candidate, count in candidates.items() if count >= support_threshold}\n",
    "    return freq_candidates, dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent 2-itemsets: 9\n",
      "[(368, 682), (368, 829), (39, 825), (704, 825), (39, 704), (227, 390), (390, 722), (217, 346), (789, 829)]\n",
      "Number of frequent 3-itemsets: 1\n",
      "[(39, 704, 825)]\n"
     ]
    }
   ],
   "source": [
    "### step d: iterate over steps b and c until no more frequent itemsets are found\n",
    "L = L1\n",
    "while(len(L)>0):\n",
    "    C = generate_candidates(L, L1)\n",
    "    L, dict = filter_candidates(baskets, C, len(L[0])+1, s)\n",
    "    if len(L) > 0:\n",
    "        print('Number of frequent {}-itemsets: {}'.format(len(L[0]), len(L)))\n",
    "        print(L)\n",
    "        frequent_itemsets.append(dict)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Get association rules\n",
    "Support of rule X → Y is the number of transactions that contain X⋃Y\n",
    "Confidence of rule X → Y is the fraction of transactions containing X⋃Y in all transactions that contain X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent_itemsets[0] # singletons\n",
    "# frequent_itemsets[1] # doubletons\n",
    "# frequent_itemsets[2] # tripletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf(XUY, X, frequent_itemsets):\n",
    "    XUY_support = frequent_itemsets[len(XUY) - 1][XUY]\n",
    "    X_support = frequent_itemsets[len(X) - 1][X]\n",
    "    return XUY_support / X_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rule(left, right, conf):\n",
    "    print('{' + ','.join(map(str, left)) + '} -> ' + str(right[0]) + ' conf: ' + str(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{704} -> 825 conf: 0.6142697881828316\n",
      "{704} -> 39 conf: 0.617056856187291\n",
      "{227} -> 390 conf: 0.577007700770077\n",
      "{704,825} -> 39 conf: 0.9392014519056261\n",
      "{39,825} -> 704 conf: 0.8719460825610783\n",
      "{39,704} -> 825 conf: 0.9349593495934959\n"
     ]
    }
   ],
   "source": [
    "### construct rules out of frequent itemsets since the support of the rule should beyond threshold\n",
    "confidence = 0.5\n",
    "for k_itemsets in frequent_itemsets[1:]:\n",
    "    for k_itemset in k_itemsets:\n",
    "        for i in range(len(k_itemset)):\n",
    "            right = (k_itemset[i],) # pick one item out\n",
    "            left = tuple(sorted(set(k_itemset) - set(right)))\n",
    "            if conf(k_itemset, left, frequent_itemsets) >= confidence:\n",
    "                print_rule(left, right, conf(k_itemset, left, frequent_itemsets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e2879a7bd479cbeb897d9ec143fa346b859f6c8c1f0cd19f937abde91010ec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
